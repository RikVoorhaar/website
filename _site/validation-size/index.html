<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.20.1 by Michael Rose
  Copyright 2013-2019 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->

<!-- <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script> -->

<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>

<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>How big should my validation set be? - Rik Voorhaar</title>
<meta name="description" content="Cross validation is extremely important, but how should we choose the size of our validation and test sets?">


  <meta name="author" content="Dr. Rik Voorhaar">


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Rik Voorhaar">
<meta property="og:title" content="How big should my validation set be?">
<meta property="og:url" content="https://blog.rikvoorhaar.com/validation-size/">


  <meta property="og:description" content="Cross validation is extremely important, but how should we choose the size of our validation and test sets?">



  <meta property="og:image" content="https://blog.rikvoorhaar.com/imgs/teasers/validation-data.jpg">





  <meta property="article:published_time" content="2020-08-26T00:00:00-05:00">





  

  


<link rel="canonical" href="https://blog.rikvoorhaar.com/validation-size/">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": "Rik Voorhaar",
      "url": "https://blog.rikvoorhaar.com/"
    
  }
</script>






<!-- end _includes/seo.html -->


<link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Rik Voorhaar Feed">

<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<!-- <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css"> -->
<script src="https://kit.fontawesome.com/ca9a31e360.js" crossorigin="anonymous"></script>


<!--[if IE]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->
<link rel="shortcut icon" type="image/x-icon" href="/favicon.ico">

<!-- end custom head snippets -->
<link rel="preconnect" href="https://fonts.googleapis.com"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link href="https://fonts.googleapis.com/css2?family=Bitter:wght@500;600;700;800&family=Open+Sans:ital,wght@0,300;0,400;0,500;0,600;0,700;0,800;1,300;1,400;1,500;1,600;1,700;1,800&display=swap" rel="stylesheet">
  </head>

  <body class="layout--posts">
    <nav class="skip-links">
  <h2 class="screen-reader-text">Skip links</h2>
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
          <a class="site-logo" href="/"><img src="/assets/images/logo_name.svg" alt=""></a>
        
        <a class="site-title" href="/">
           
          
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/cv/">CV</a>
            </li><li class="masthead__menu-item">
              <a href="/">Blog</a>
            </li><li class="masthead__menu-item">
              <a href="/about/">Hobbies</a>
            </li></ul>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      <div class="page__hero-background"> </div>





<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person">

  
    <div class="author__avatar">
      
        <img src="/imgs/avatar.jpg" alt="Dr. Rik Voorhaar" itemprop="image">
      
    </div>
  

  <div class="author__content">
    
      <h3 class="author__name" itemprop="name">Dr. Rik Voorhaar</h3>
    
    
      <div class="author__bio" itemprop="description">
        <p>ML Software Developer and curious mind</p>

      </div>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Contact info and socials</button>
    <ul class="author__urls social-icons">
      
        <li itemprop="homeLocation" itemscope itemtype="https://schema.org/Place">
          <i class="fas fa-fw fa-map-marker-alt" aria-hidden="true"></i> <span itemprop="name">Copenhagen, Denmark</span>
        </li>
      

      
        
          
            <li><a href="mailto:rik.voorhaar@gmail.com" rel="nofollow noopener noreferrer"><i class="far fa-fw fa-envelope" aria-hidden="true"></i><span class="label">rik.voorhaar@gmail.com</span></a></li>
          
        
          
            <li><a href="https://github.com/RikVoorhaar" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i><span class="label">GitHub</span></a></li>
          
        
          
            <li><a href="https://www.facebook.com/WH.Voorhaar" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span class="label">Facebook</span></a></li>
          
        
          
            <li><a href="https://discord.com/users/354966598643220480" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-discord" aria-hidden="true"></i><span class="label">Discord</span></a></li>
          
        
          
            <li><a href="https://www.linkedin.com/in/rik-voorhaar" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span class="label">LinkedIn</span></a></li>
          
        
          
            <li><a href="https://www.last.fm/user/Tilpo" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-lastfm-square" aria-hidden="true"></i><span class="label">Last.fm</span></a></li>
          
        
          
            <li><a href="https://www.goodreads.com/user/show/62542056-tilpo" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-goodreads" aria-hidden="true"></i><span class="label">Goodreads</span></a></li>
          
        
          
            <li><a href="https://steamcommunity.com/profiles/76561197996562422" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-steam" aria-hidden="true"></i><span class="label">Steam</span></a></li>
          
        
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
  </div>



  <div class="archive">
    <br>
    
      <h1 id="page-title" class="page__title">How big should my validation set be?</h1>
    
    <p>In machine learning it is important to split your data into a training, validation and test set. People often use a heuristic like suggesting to split your data into sizes of 50/25/25 or 70/20/10 or something like that. Can we do better than a heuristic?</p>

<p>We can also do such analysis to give estimates in the uncertainty in the test scores of our models. For example, suppose we say “our model has 98% accuracy on validation and 96% on the test set”, and the test set consists of 100 samples, then what is the uncertainty in this estimate of the accuracy? This also allows us to say with certainty whether or not a model is better than another.</p>

<h2 id="the-beta-prior">The Beta prior</h2>

<p>Let’s suppose we have some classication model \(f\colon \mathbb R^n\to \{0,...,n\}\) on n-dimensional data, which we trained on \(N_{train}\) training data points \((X^i_{train},y^i_{train})_{1\leq i\leq N_{train}}\). We now want to evaluate the accuracy of this model on test data \((X^i_{test},y^i_{test})_{1\leq i \leq N_{test}}\). We can model the chance that our model correctly guesses a test value with a probality \(p\):</p>

\[P(f(X_{test}^i) = y_{test}^i) = p\]

<p>This is assuming that all the test samples are equally ‘hard’ for our model. In practice this probality of \(p\) can vary, but this is more difficult to model.</p>

<p>Suppose now that \(N_{test}=100\) and we got the right answer 96/100 times. Then an unbiased estimator for this probality \(p\) is simply \(p=96\%\), but this says nothing about the probality distribution of \(p\).</p>

<p>A common way to model probabilities is using the <a href="https://en.wikipedia.org/wiki/Beta_distribution">Beta distribution</a> \(p\sim \mathrm{Beta}(\alpha,\beta)\). This is distribution is supported on \([0,1]\), so it’s values can be interpeted as probabilities. It depends on two parameters \(\alpha,\beta\), and has density function:</p>

\[C x^{\alpha-1}(1-x)^{\beta-1},\]

<p>where \(C = \Gamma(\alpha+\beta)/\Gamma(\alpha)\Gamma(\beta)\) is a normalization constant. Now we just need to figure out how to estimate the parameters \(\alpha,\beta\) from our experiment.</p>

<p>Before we did any experiment and tried our model on the test set, we know nothing about the probability \(p\). We can therefore model it as a uniform distribution on \([0,1]\), or equivalently \(p\sim \mathrm{Beta}(1,1)\). This is known as the <em>prior distribution</em> for the random variable \(p\). After our experiment we have new information, and we can update the values of \(\alpha\) and \(\beta\) to get a <em>posterior distribution</em> for \(p\). This process is known as Bayesian inference.</p>

<p>In this case, if we have 96 sucesses and 4 failures on the test set we should update our posterior to \(p\sim \mathrm{Beta}(96+1,4+1)\). This update rule is known as the <a href="https://en.wikipedia.org/wiki/Rule_of_succession">rule of succession</a>. If we choose the prior \(p\sim\mathrm{Beta}(0,0)\) we get posterior \(p\sim \mathrm{Beta}(96,4)\), but this has the notable disadvantage that if we somehow get 100% on the test, the resulting distribution takes value 1 with 100% probability, which is not realistic. Adding +1 to both \(\alpha\) and \(\beta\) is a bit more conservative in extreme cases. In general the parameters of a posterior distribution can be very difficult to compute, but in this case there is such a simple formula because the beta distribution and the binomial distribution are <em>conjugate priors</em>.</p>

<p>In short:</p>

<blockquote>
  <p>If we measure \(n\) successes and \(m\) failures, we model the resulting probability by \(p\sim \mathrm{Beta}(n+1,m+1)\).</p>
</blockquote>

<h2 id="quantifying-uncertainty-in-test-results">Quantifying uncertainty in test results</h2>

<p>With that out of the way, in our example of getting 96/100 right on the test set, what is the uncertainty for the probability \(p\)? We begin by plotting the distribution for \(p\):</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Define a random variable
</span><span class="n">rv</span> <span class="o">=</span> <span class="n">scipy</span><span class="p">.</span><span class="n">stats</span><span class="p">.</span><span class="n">beta</span><span class="p">(</span><span class="mi">97</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>

<span class="c1"># Plot its distribution
</span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">num</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">ticks</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">num</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">ticks</span><span class="o">=</span><span class="n">ticks</span><span class="p">,</span><span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">t</span><span class="si">:</span><span class="p">.</span><span class="mi">1</span><span class="n">f</span><span class="si">}</span><span class="s">"</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">ticks</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Probility density function of Beta(97,5)"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">rv</span><span class="p">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"mean=</span><span class="si">{</span><span class="n">rv</span><span class="p">.</span><span class="n">mean</span><span class="p">()</span><span class="si">}</span><span class="s">, std=</span><span class="si">{</span><span class="n">rv</span><span class="p">.</span><span class="n">std</span><span class="p">()</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/imgs/validation-size_3_0.svg" alt="svg" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mean=0.9509803921568627, std=0.021274143540891813
</code></pre></div></div>

<p>Here we see that the actual value of \(p\) could be anywhere in the roughly \(92-98\%\) range, and our estimate of \(p\) is in fact \(p=95\pm2.1\%\). The standard deviation of \(\mathrm{Beta}(\alpha,\beta)\) is given by</p>

\[\sigma(Beta(\alpha,\beta)) = \sqrt{\frac{\alpha\beta}{(\alpha+\beta)^2}}\frac1{\sqrt{\alpha+\beta+1}} = \frac{\sqrt{\hat p(1-\hat p)}}{\sqrt{N+3}}\]

<p>Here \(N=\alpha+\beta\) is the total number of trials in our experiment and \(\hat p = (\alpha+1)/(\alpha+\beta+2)\) is the estimated probability after our experiment. This shows that the uncertainty goes down with the square root of the number of trials (which is true for pretty much anything), and that it depends non-trivially on the estimated probability \(\hat p\). This is important, because it means the better our model performs (test score closer to 100%), the lower the uncertainty is in this test score.</p>

<h2 id="which-model-is-better">Which model is better?</h2>

<p>Now suppose we have a second model, (call it Model B) and we test it on the same test set. Now we get a score of 98%! We think that this Model B is better than Model A, but is it? Let’s plot the Beta distribution for both probabilities:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">rv1</span> <span class="o">=</span> <span class="n">scipy</span><span class="p">.</span><span class="n">stats</span><span class="p">.</span><span class="n">beta</span><span class="p">(</span><span class="mi">96</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span>
<span class="n">rv2</span> <span class="o">=</span> <span class="n">scipy</span><span class="p">.</span><span class="n">stats</span><span class="p">.</span><span class="n">beta</span><span class="p">(</span><span class="mi">98</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.8</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">num</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">ticks</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.8</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">num</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">ticks</span><span class="o">=</span><span class="n">ticks</span><span class="p">,</span><span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">t</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s">"</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">ticks</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Probility density function of Beta(96,4) and Beta(98,2)"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">rv1</span><span class="p">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">),</span><span class="n">label</span><span class="o">=</span><span class="s">"96% accuracy"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">rv2</span><span class="p">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">),</span><span class="n">label</span><span class="o">=</span><span class="s">"98% accuracy"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/imgs/validation-size_6_0.svg" alt="svg" /></p>

<p>Just going by the probability distrubutions we see a lot of overlap. We can actually estimate the probability that the second model is better than the first model. (Or rather, we can estimate the probability of rejecting the null hypothesis that the second model is not better than the first.) A crude but simple way to do this is to sample both distrubutions and then count the number of values in one distrubution that are bigger than the other. Unfortunately this is not efficient, and requires a lot of samples to produce an accurate probability.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">N</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mf">1e+6</span><span class="p">)</span>
<span class="n">rv1</span> <span class="o">=</span> <span class="n">scipy</span><span class="p">.</span><span class="n">stats</span><span class="p">.</span><span class="n">beta</span><span class="p">(</span><span class="mi">96</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span>
<span class="n">rv2</span> <span class="o">=</span> <span class="n">scipy</span><span class="p">.</span><span class="n">stats</span><span class="p">.</span><span class="n">beta</span><span class="p">(</span><span class="mi">98</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="n">p_value</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">rv1</span><span class="p">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">N</span><span class="p">)</span><span class="o">&gt;</span><span class="n">rv2</span><span class="p">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">N</span><span class="p">))</span><span class="o">/</span><span class="n">N</span>

<span class="k">print</span><span class="p">(</span><span class="s">"probability Model A better than Model B"</span><span class="p">,</span> <span class="n">p_value</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>probability Model A better than Model B 0.184565
</code></pre></div></div>

<p>There are also several statistical tests out there that do something similar. Two noteworthy ones are the fisher exact probability test, which works well for small sample sizes. And the chi-squared test, which is more efficient but innacurate for small sample sizes.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">_</span><span class="p">,</span><span class="n">p_value</span> <span class="o">=</span> <span class="n">scipy</span><span class="p">.</span><span class="n">stats</span><span class="p">.</span><span class="n">fisher_exact</span><span class="p">([[</span><span class="mi">96</span><span class="p">,</span><span class="mi">98</span><span class="p">],[</span><span class="mi">4</span><span class="p">,</span><span class="mi">2</span><span class="p">]],</span><span class="n">alternative</span><span class="o">=</span><span class="s">'less'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Fisher exact p-value:"</span><span class="p">,</span> <span class="n">p_value</span><span class="p">)</span>

<span class="n">_</span><span class="p">,</span><span class="n">p_value</span><span class="p">,</span><span class="n">_</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">scipy</span><span class="p">.</span><span class="n">stats</span><span class="p">.</span><span class="n">chi2_contingency</span><span class="p">([[</span><span class="mi">96</span><span class="p">,</span><span class="mi">98</span><span class="p">],[</span><span class="mi">4</span><span class="p">,</span><span class="mi">2</span><span class="p">]])</span>
<span class="k">print</span><span class="p">(</span><span class="s">"chi-squared p-value:"</span><span class="p">,</span> <span class="n">p_value</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>

</code></pre></div></div>

<p>Either way, the conclusion is that Model B is expected to be better than Model A, but the difference is not statisticaly significant.</p>

<h2 id="many-models">Many models</h2>

<p>Now what if we don’t just have 2 models, but dozens of different models. For example because our models depend on some hyperparameters for which we tried many different values. Then out of all these models, we want to know which is the best, and assign a probability to this. This leads to the <a href="https://xkcd.com/882/">multiple testing problem</a>. For example, if we have 100 different models, each getting 95% accuracy, then purely by coincidence a few of these models might be getting scores like 97% or 98% and will seem better. Since the error in the score scales with the inverse square root of the size of the test set, this problem is difficult to eliminate by just choosing a larger test set.</p>

<p>Suppose we have \(n\) models with test scores \(p_1,\dots, p_n\), then the probability that \(p_1\) is the biggest can by computed by</p>

\[P(p_1&gt;\max(p_2,\dots,p_n)) = P((p_1&gt;p_2)\cup (p_1&gt;p_3)\cup\dots\cup(p_1&gt;p_n))\]

<p>This probability is very difficult to compute exactly because the events are not independent. But we do get a very useful upper bound if we assume independence:</p>

\[P(p_1&gt;\max(p_2,\dots,p_n)) \leq \sum_{i=2}^n P(p_1&gt;p_i)\]

<p>These individual probabilities can then be computed with the exact Fisher test or the chi-squared test as outline above. The important thing to note is that if all these probabilities are on the same order, the probability that a particular model can be reliably identified as the best model scales linearly with the number of models we compare it to.</p>

<p>In short:</p>
<blockquote>
  <p>Twice the number of different models means twice the amount of precision in test score needed, which in turn means 4 times the size of the test set.</p>
</blockquote>

<h2 id="why-split-test--validation-sets-are-important">Why split test / validation sets are important</h2>

<p>We don’t actually use the validation set to determine which out of all our models is the best. Sometimes we might train a model, see how it does on the validation set. Then we might tweak some particular hyperparameter of the model to see if it improves the validation score. Often times it has no significant effect, and we revert it back to it’s default value. Even if we do this ten times, we don’t consider the resulting models to be ten different models; we consider them as equivalent. But it’s also very possible that changing some parameter significantly improved the validation score just by coincidence, and in practice it did not do much. This is roughly what data scientists refer to when they say that a model can “learn the test set”, although this can be also refer to our model picking up on specific biases present in the test set. Intuition is very important here as well. We use the validation set not just to determine which of our models is the best, but also to estimate whether small variations of models are significantly better or worse.</p>

<p>At the end of the day, we will probably consider only a couple models to be among the best, and those are the ones we should try on the test set. We can then use the methods outlined above to determine which of these is the best.</p>

<h2 id="so-how-big-should-my-validation--test-set-be">So how big should my validation / test set be?</h2>

<p>It can be difficult to estimate a good size \(N\) of the validation set in practice, since it depends on some assumptions of our models. It depends on the following variables:</p>

<ul>
  <li>\(n_m\): The number of different models we will compare with similar performance.</li>
  <li>\(p\): The test score of the best model (on a scale of 0 to 1)</li>
  <li>\(\sigma\): The difference in test score between the best and second best model</li>
</ul>

<p>We then have</p>

\[N \simeq \frac{n_m^2 p(1-p)}{\sigma^2}\]

<p>The number \(n_m\) is mainly relevant if we intend to compare several models that are roughly similar in quality, for example if we’re doing hyper parameter optimization. If we expect the difference between the third-best and second-best model to be around the same as the difference between the second-best and the best model, we can leave this parameter equal to 1 in our estimation.</p>

<p>The same formula also applies to estimating the size of a test set. If we just want to get an estimate of the test score of a single model, or if we’re just comparing two models, then we can leave \(n_m\) at 1, but if we’re comparing more models we need to take this into account. This is especially true since if we’re comparing different models on the test set we already expect them to have quite similar performance.</p>

<p>The precision \(\sigma\) and quality \(p\) have an interesting interaction that works in our favor. If we compare two relatively bad models, say with qualities \(p\) around 50%, then probably we don’t need super high precision – it’s probably doesn’t matter to us whether the model has score of 50% or 50.1%, so a 1% precision is fine. The factor \(p(1-p)\) is then roughly 0.25, so we need a validation size of roughly \(0.25/(0.01)^2 = 2500\) samples.</p>

<p>On the other hand if we have two models with score around 99.0%, we would need a precision of at least 0.1%. Without the \(p(1-p)\) factor, this means we would need one million samples, but \(p(1-p)\simeq 0.01\), so that we only need around 10000 samples.</p>

<h1 id="real-world-example-different-models-on-mnist">Real world example: different models on MNIST</h1>

<p>We can use everything we have learned so far to guide us in the experimental design of a real project. Let’s take <a href="http://yann.lecun.com/exdb/mnist/">the over-used MNIST dataset</a> as an example. For convenience we will use <a href="https://www.kaggle.com/c/digit-recognizer">the dataset found on kaggle</a>. This is already preprocessed into a .csv file, but it does have less samples than original (it is split into an unlabeled test-set).</p>

<p>As a first step we will just import the model and train a simple linear model on it. This is a baseline, and it will help us estimate the quality of the model. To start off we will do an 80-20 training/test split, just to evaluate our baseline.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="c1"># Load dataset
</span><span class="n">mnist</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">"train.csv"</span><span class="p">)</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">mnist</span><span class="p">[</span><span class="s">"label"</span><span class="p">]</span>
<span class="n">mnist</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="s">"label"</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># Do simple train-test split
</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">mnist</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span> 
</code></pre></div></div>

<h2 id="baseline-model">Baseline model</h2>

<p>The baseline model we will be using is a linear support vector classifier (LinearSVC in scikit-learn). This is a very simple model, and is relatively quick to train even on large data. We will then score it by accuracy on the test set. Using the formula we saw before for the standard deviation of the beta distribution, we can estimate the error in this score:</p>

\[\sigma = \frac{\sqrt{\hat p(1-\hat p)}}{\sqrt{N+3}}\]

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span>  <span class="n">LinearSVC</span>

<span class="c1"># Fit linear support vector classification model
</span><span class="n">model</span> <span class="o">=</span> <span class="n">LinearSVC</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Compute accuracy score and uncertainty in score
</span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">)</span>
<span class="n">error</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">accuracy</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">accuracy</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span><span class="o">+</span><span class="mi">3</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'Linear SVC error: </span><span class="si">{</span><span class="n">accuracy</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s"> ± </span><span class="si">{</span><span class="n">error</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s">%'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Linear SVC error: 87.08 ± 0.37%
</code></pre></div></div>

<h2 id="experimental-setup">Experimental setup</h2>

<p>This gives us a reasonable baseline. Any reasonable model shouldn’t perform worse than this. The current size of the validation is not ideal, since the error in the score is still relatively big (e.g. we can’t reliably identify a 0.5% improvement). But making it much bigger is also clearly not good, since this will sacrifice the quality of the model too much, and even if we make it twice bigger we only expect the error to become smaller by a factor of \(\sqrt{2}\).</p>

<p>Perhaps we can work here with an 80/10/10 split, and appreciate the fact that we should not compare too many models. For example, hyperparameter tuning will likely result in overfitting on the validation data and relatively poor performance on the test set, because it is difficult to reliably identify small improvements.</p>

<p>We can use this baseline model to design the following experiment:</p>
<ul>
  <li>Divide the data into 80/10/10% training, validation and test set.</li>
  <li>Only test a handful of models, preferably very different ones:
    <ul>
      <li>SVM with RBF kernel</li>
      <li>Fully connected neural net</li>
      <li>Convolutional neural net</li>
      <li>K-nearest-neighbors</li>
      <li>XGBoost</li>
    </ul>
  </li>
  <li>No hyperparameter tuning. Only try a handful of hyperparameter for each model, and use standard parameters unless there is statistically significant improvement.</li>
  <li>Only compare the best 2 or 3 models on the test set, unless the validation set is enough to reliably identify the best model.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Split data into train, validation and test
</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">mnist</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span> 
<span class="n">X_test</span><span class="p">,</span> <span class="n">X_val</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">y_val</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Helper function for estimating the error in the accuracy
</span><span class="k">def</span> <span class="nf">print_score_error</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s">""</span><span class="p">,</span> <span class="n">test_data</span> <span class="o">=</span> <span class="bp">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">test_data</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">test_data</span> <span class="o">=</span> <span class="n">y_val</span>

    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span> <span class="o">==</span> <span class="n">test_data</span><span class="p">)</span>
    <span class="n">error</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">accuracy</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">accuracy</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span><span class="o">+</span><span class="mi">3</span><span class="p">))</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s"> error: </span><span class="si">{</span><span class="n">accuracy</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s"> ± </span><span class="si">{</span><span class="n">error</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s">%'</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">accuracy</span><span class="p">,</span> <span class="n">error</span>
</code></pre></div></div>

<h2 id="support-vector-machines">Support vector machines</h2>

<p>Above we used support vector classification with a linear kernel. Using a different kernel can significantly improve performance by making the decision boundaries non-linear. This does however increase the number of parameters of the model, and makes it harder to train. We will be trying an RBF kernel and a degree 3 polynomial kernel. We won’t be touching any of the other parameters of this model.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>

<span class="n">svc_rbf</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s">'rbf'</span><span class="p">)</span>
<span class="n">svc_rbf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">svc_rbf_acc</span><span class="p">,</span> <span class="n">svc_rbf_err</span> <span class="o">=</span> <span class="n">print_score_error</span><span class="p">(</span><span class="n">svc_rbf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_val</span><span class="p">),</span><span class="s">"SVC with rbf kernel"</span><span class="p">)</span>

<span class="n">svc_pol3</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s">'poly'</span><span class="p">,</span><span class="n">degree</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">svc_pol3</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">svc_pol3_acc</span><span class="p">,</span> <span class="n">svc_pol3_err</span> <span class="o">=</span> <span class="n">print_score_error</span><span class="p">(</span><span class="n">svc_pol3</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_val</span><span class="p">),</span><span class="s">"SVC with deg 3 polynomial kernel"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>SVC with rbf kernel error: 97.38 ± 0.25%
SVC with deg 3 polynomial kernel error: 96.90 ± 0.27%
</code></pre></div></div>

<p>Both models perform already much better than the linear SVC, and while the model with rbf kernel is better, this could also be coincidental. We can estimate the chance that the model with the rbf kernel is actually better:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Helper function for comparing two models
</span><span class="k">def</span> <span class="nf">compare_models</span><span class="p">(</span><span class="n">accuracy1</span><span class="p">,</span> <span class="n">accuracy2</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">,</span> <span class="n">name1</span><span class="o">=</span><span class="s">"model1"</span><span class="p">,</span> <span class="n">name2</span><span class="o">=</span><span class="s">"model2"</span><span class="p">):</span>
    <span class="n">num_correct1</span> <span class="o">=</span> <span class="n">accuracy1</span><span class="o">*</span><span class="n">num_samples</span>
    <span class="n">num_incorrect1</span> <span class="o">=</span> <span class="n">num_samples</span> <span class="o">-</span> <span class="n">num_correct1</span>

    <span class="n">num_correct2</span> <span class="o">=</span> <span class="n">accuracy2</span><span class="o">*</span><span class="n">num_samples</span>
    <span class="n">num_incorrect2</span> <span class="o">=</span> <span class="n">num_samples</span> <span class="o">-</span> <span class="n">num_correct2</span>
    
    <span class="n">_</span><span class="p">,</span><span class="n">p_value</span> <span class="o">=</span> <span class="n">scipy</span><span class="p">.</span><span class="n">stats</span><span class="p">.</span><span class="n">fisher_exact</span><span class="p">([[</span><span class="n">num_correct1</span><span class="p">,</span><span class="n">num_correct2</span><span class="p">],[</span><span class="n">num_incorrect1</span><span class="p">,</span><span class="n">num_incorrect2</span><span class="p">]],</span><span class="n">alternative</span><span class="o">=</span><span class="s">'less'</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Probability </span><span class="si">{</span><span class="n">name1</span><span class="si">}</span><span class="s"> is better than </span><span class="si">{</span><span class="n">name2</span><span class="si">}</span><span class="s">: </span><span class="si">{</span><span class="n">p_value</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">E</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="n">compare_models</span><span class="p">(</span><span class="n">svc_rbf_acc</span><span class="p">,</span> <span class="n">svc_pol3_acc</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_val</span><span class="p">),</span> <span class="s">"(SVC with RBF kernel)"</span><span class="p">,</span> <span class="s">"(SVC with deg 3 polynomial kernel)"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Probability (SVC with RBF kernel) is better than (SVC with deg 3 polynomial kernel): 9.16E-01
</code></pre></div></div>

<p>We get a 92% chance that the RBF kernel model is better. That’s far from a guarantee, but it’s not bad.</p>

<h2 id="fully-connected-neural-net">Fully connected neural net</h2>

<p>We will use Keras to fit a 2 layer fully connected neural network. Since we don’t have that much data, we should keep the size of the hidden layers modest, otherwise we will end up with more parameters than data points. While neural networks thrive on reduncancy, and having more parameters than data points is not necessarily a problem, it is still a great recipe for overfitting.</p>

<p>It turns out that the final accuracy is not very senstive on the network architecture. Even with very aggressive regularization we do not seem to be getting an accuracy score surpassing 94%. The only thing that seems to have a significant effect is using a sigmoid or tanh activation function over the default relu, giving about 5% improvement (which is significant). All in all, it seems fully connected networks perform (significantly) worse than SVC.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">layers</span>

<span class="c1"># 2 layer fully connected model
</span><span class="n">fc_model</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="n">keras</span><span class="p">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">,)),</span>
        <span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s">'sigmoid'</span><span class="p">),</span>
        <span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">"softmax"</span><span class="p">)</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="c1"># train the model
</span><span class="n">fc_model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s">"sparse_categorical_crossentropy"</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s">"adam"</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">"accuracy"</span><span class="p">])</span>
<span class="n">fc_model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">validation_data</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">),</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Evaluate the model
</span><span class="n">prediction</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">fc_model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_val</span><span class="p">),</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">fcnn_acc</span><span class="p">,</span> <span class="n">fcnn_err</span> <span class="o">=</span> <span class="n">print_score_error</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span><span class="s">"Fully connected nn"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Fully connected nn error: 92.19 ± 0.41%
</code></pre></div></div>

<h2 id="convolutional-neural-net">Convolutional neural net</h2>

<p>Convolutional neural networks are supposed to be the bread and butter of image classifcation. In fact <a href="https://keras.io/examples/vision/mnist_convnet/">the keras docs use a covnet on mnist as an example</a>. We can copy the architecture straight from there.</p>

<p>Here we seem to be getting significantly better scores than with the fully connected nerual network, and in fact the best scores so far.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Define the model
</span><span class="n">cnn_model</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="n">keras</span><span class="p">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">),</span>
        <span class="n">layers</span><span class="p">.</span><span class="n">Reshape</span><span class="p">((</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">1</span><span class="p">)),</span>
        <span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s">"relu"</span><span class="p">),</span>
        <span class="n">layers</span><span class="p">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span>
        <span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s">"relu"</span><span class="p">),</span>
        <span class="n">layers</span><span class="p">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span>
        <span class="n">layers</span><span class="p">.</span><span class="n">Flatten</span><span class="p">(),</span>
        <span class="n">layers</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">),</span>
        <span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">"softmax"</span><span class="p">),</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="c1"># Train the model
</span><span class="n">cnn_model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s">"sparse_categorical_crossentropy"</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s">"adam"</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">"accuracy"</span><span class="p">])</span>
<span class="n">cnn_model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">validation_data</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">),</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Evaluate the model
</span><span class="n">prediction</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">cnn_model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_val</span><span class="p">),</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">covnet_acc</span><span class="p">,</span> <span class="n">covnet_err</span> <span class="o">=</span> <span class="n">print_score_error</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span><span class="s">"Convolutional neural net"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Convolutional neural net error: 98.26 ± 0.20%
</code></pre></div></div>

<p>Let’s compare the convolutional network’s scores to the SVC with RBF kernel. We get that the convolutional net is better than the SVC on the validation set with an odds ratio of 1000, which is certainly statistically significant.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">compare_models</span><span class="p">(</span><span class="n">svc_rbf_acc</span><span class="p">,</span> <span class="n">covnet_acc</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_val</span><span class="p">),</span><span class="s">"(SVC with RBF kernel)"</span><span class="p">,</span><span class="s">"(Convolutional neural net)"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Probability (SVC with RBF kernel) is better than (Convolutional neural net): 9.52E-05
</code></pre></div></div>

<h2 id="k-nearest-neighbors">K-nearest neighbors</h2>
<p>The K-nearest neighbors model is another simple, but often effective model for classiciation. The most important parameter is the number of neighbors used in the model, so we can use this model with various numbers of neighbors to see if it affects the accuracy. It turns out irrespective of this parameter the accuracy is a bit worse than the SVC method.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>

<span class="k">for</span> <span class="n">n_neighbors</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">9</span><span class="p">):</span>
    <span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">n_neighbors</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">knn</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

    <span class="n">knn_acc</span><span class="p">,</span> <span class="n">knn_err</span> <span class="o">=</span> <span class="n">print_score_error</span><span class="p">(</span><span class="n">knn</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_val</span><span class="p">),</span> <span class="sa">f</span><span class="s">"KNN with </span><span class="si">{</span><span class="n">n_neighbors</span><span class="si">}</span><span class="s"> neighbors"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>KNN with 3 neighbors error: 96.64 ± 0.28%
KNN with 4 neighbors error: 96.43 ± 0.29%
KNN with 5 neighbors error: 96.64 ± 0.28%
KNN with 6 neighbors error: 96.36 ± 0.29%
KNN with 7 neighbors error: 96.29 ± 0.29%
KNN with 8 neighbors error: 96.17 ± 0.30%
</code></pre></div></div>

<h2 id="xgboost">XGBoost</h2>

<p>XGBoost is a popular package for gradient boosted trees. It performs exceptionally well on many problems. However, for this particular problem it seems to perform worse than the convolutional neural network, and adjusting the parameters of the model does not seem to fix this problem.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">xgboost</span> <span class="k">as</span> <span class="n">xgb</span>

<span class="c1"># Create a dataset in the right form
</span><span class="n">dtrain</span> <span class="o">=</span> <span class="n">xgb</span><span class="p">.</span><span class="n">DMatrix</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">dval</span> <span class="o">=</span> <span class="n">xgb</span><span class="p">.</span><span class="n">DMatrix</span><span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">y_val</span><span class="p">)</span>

<span class="c1"># Parameters of the model
</span><span class="n">param</span> <span class="o">=</span> <span class="p">{</span><span class="s">'objective'</span><span class="p">:</span><span class="s">'multi:softmax'</span><span class="p">,</span> <span class="s">'nthread'</span><span class="p">:</span> <span class="mi">15</span><span class="p">,</span> <span class="s">"eval_metric"</span><span class="p">:</span> <span class="s">"merror"</span><span class="p">,</span><span class="s">"num_class"</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span> <span class="s">"max_depth"</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>

<span class="c1"># Train and evaluate the model
</span><span class="n">bst</span> <span class="o">=</span> <span class="n">xgb</span><span class="p">.</span><span class="n">train</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">dtrain</span><span class="p">)</span>
<span class="n">preds</span> <span class="o">=</span> <span class="n">bst</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">dval</span><span class="p">)</span>
<span class="n">xgb_acc</span><span class="p">,</span> <span class="n">xgb_err</span> <span class="o">=</span> <span class="n">print_score_error</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="sa">f</span><span class="s">"xgboost"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>xgboost error: 94.60 ± 0.35%
</code></pre></div></div>

<h2 id="conclusion">Conclusion</h2>

<p>Out of all the models tested, it seems that the convolutional neural network performs signficantly better than the others. Since we did not perform any hyperparameter optimization on it, the performance on the validation set should be an unbiased estimate of its performance on the test set. We can also conclude that our validation set size was big enough to tell which of the models we tried has the best performance. We could still perform hyperparameter optimization on the convolutional network to potentially improve performance further.</p>

<p>Let’s now try the convolutional model on our test set to evaluate it.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">prediction</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">cnn_model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">covnet_acc</span><span class="p">,</span> <span class="n">covnet_err</span> <span class="o">=</span> <span class="n">print_score_error</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span><span class="s">"Convolutional neural net"</span><span class="p">,</span> <span class="n">test_data</span><span class="o">=</span><span class="n">y_test</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Convolutional neural net error: 98.69 ± 0.18%
</code></pre></div></div>

<p>We actually see a slight improvement when evaluating the model on the test set. The difference is roughly two standard deviations, which may be statistically significant. This can indicate a bias in the test or validation set, although in this case it could also be purely coincidental.</p>

<h1 id="regression-models-and-other-metrics">Regression models and other metrics</h1>

<p>So far our discussion has been centered around the accuracy metric for classification problems. In principle we can use any metric, but each metric does require some analysis to estimate error. All metrics can be interpreted as a random variable, and we can in principle derive estimates of the distribution, either theoretically or through empirical methods like bootstrapping.</p>

<p>For example the mean square error for regression is defined by</p>

\[\mathrm{MSE} = \frac1N \sum_{i=1}^N(y_i-\hat y_i)^2\]

<p>where \(y_i\) are the test labels, and \(\hat y_i\) the predicted values. This can be interpreted as the sample mean of the random variable \((Y-\hat Y)^2\). Sample means tend to be normally distributed if we plug in enough samples, so we could model the distribution of MSE as a normal distribution (or t-distribution), with variance obtained from the sample variance of this random variable:</p>

\[\sigma^2 = \frac{1}{N-1}\sum_{i=1}^N \left((y_i-\hat y_i)^2-\mathrm{MSE}\right)^2\]

<p>And this method works for any metric that is obtained as a mean over all samples. Most metrics are of this form, but not all metrics (notably the area under ROC curve metric).</p>

<p>In the case of MSE we may be able to do better. A central assumption of least squares regression is that the residuals \(Y-\hat Y\) are normally distributed. Recall that the sum of \(N\) (standard) normally distributed independent random variables follows a chi-squared distribution. In other words if we define the bias \(B\) by</p>

\[B = \frac1n\sum y_i-\hat y_i\]

<p>Then \(Y-\hat Y\) is normally distributed with mean \(B\) and variance \(\mathrm{MSE}-B^2\) (ignoring the Bessel correction). Therefore</p>

\[\chi_Y := \sum_{i=1}^N \frac{(y_i-\hat y_i)^2}{\sqrt{\mathrm{MSE}-B^2}}\]

<p>has a non-central chi-squared distribution with \(N\) degrees of freedom and mean \(\lambda = N \cdot \mathrm{MSE}\). The variance of \(\chi_Y\) is \(2N(1+2 \mathrm{MSE})\), so we can easily deduce that</p>

\[\mathrm{Var}\left(\frac1N\sum_{i=1}^N(y_i-\hat y_i)^2\right) = \frac{2(\mathrm{MSE}-B^2)(1+2\mathrm{MSE})}{N}\]

<p>which may be a more accurate measure.</p>

<h1 id="summary">Summary</h1>

<p>The big takeaway from all of this is that we should keep the error in our performance metrics into account both during development and evaluation. It can be very easy to mistake small improvements in evaluation metrics for genuine increase in performance if we don’t have an estimate of the precision in our metrics. Also unless there is reason to think the test set may be biased in some way, there is no problem with comparing multiple models on the test set, so long as we take statistical significance into account.</p>


Recent posts




<div class="entries-grid">
  
    



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/imgs/teasers/gmres-teaser.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/gmres/" rel="permalink">GMRES: or how to do fast linear algebra
</a>
      
    </h2>
    


  <p class="page__meta">

    
      
      <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
      <time datetime="2022-03-10T00:00:00-06:00">March 10, 2022</time>
    

    
      
        <br \>
      
    

    
      
      

      <i class="far fa-fw fa-clock" aria-hidden="true"></i>
      
        16 minute read
      
    

  </p>

    <p class="archive__item-excerpt" itemprop="description">Linear least-squares system pop up everywhere, and there are many fast way to solve them. We’ll be looking at one such way: GMRES.
</p>
  </article>
</div>

  
    



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/imgs/teasers/discrete-function-tensor.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/discrete-function-tensor/" rel="permalink">Machine learning with discretized functions and tensors
</a>
      
    </h2>
    


  <p class="page__meta">

    
      
      <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
      <time datetime="2022-03-10T00:00:00-06:00">March 10, 2022</time>
    

    
      
        <br \>
      
    

    
      
      

      <i class="far fa-fw fa-clock" aria-hidden="true"></i>
      
        18 minute read
      
    

  </p>

    <p class="archive__item-excerpt" itemprop="description">We recently made a paper about supervised machine learning using tensors, here’s the gist of how this works.
</p>
  </article>
</div>

  
    



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/imgs/teasers/st-vitus-rank-10.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/low-rank-matrix/" rel="permalink">Low-rank matrices: using structure to recover missing data
</a>
      
    </h2>
    


  <p class="page__meta">

    
      
      <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
      <time datetime="2021-09-26T00:00:00-05:00">September 26, 2021</time>
    

    
      
        <br \>
      
    

    
      
      

      <i class="far fa-fw fa-clock" aria-hidden="true"></i>
      
        10 minute read
      
    

  </p>

    <p class="archive__item-excerpt" itemprop="description">A lot of data is naturally of ‘low rank’. I will explain what this means, and how to exploit this fact.
</p>
  </article>
</div>

  
    



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/imgs/python_docx/doc_comparison.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/python-docx/" rel="permalink">How to edit Microsoft Word documents in Python
</a>
      
    </h2>
    


  <p class="page__meta">

    
      
      <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
      <time datetime="2021-08-29T00:00:00-05:00">August 29, 2021</time>
    

    
      
        <br \>
      
    

    
      
      

      <i class="far fa-fw fa-clock" aria-hidden="true"></i>
      
        6 minute read
      
    

  </p>

    <p class="archive__item-excerpt" itemprop="description">Parsing and editing Word documents automatically can be extremely useful, but doing it in Python is not that straightforward.
</p>
  </article>
</div>

  
    



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/imgs/teasers/st-vitus-deblurred.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/deconvolution-part4/" rel="permalink">Blind deconvolution #4: Blind deconvolution
</a>
      
    </h2>
    


  <p class="page__meta">

    
      
      <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
      <time datetime="2021-05-31T00:00:00-05:00">May 31, 2021</time>
    

    
      
        <br \>
      
    

    
      
      

      <i class="far fa-fw fa-clock" aria-hidden="true"></i>
      
        6 minute read
      
    

  </p>

    <p class="archive__item-excerpt" itemprop="description">Finally, let’s look at how we can automatically sharpen images, without knowing how they were blurred in the first place.
</p>
  </article>
</div>

  
    



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/imgs/teasers/cow-weird-blur.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/deconvolution-part3/" rel="permalink">Blind Deconvolution #3: More about non-blind deconvolution
</a>
      
    </h2>
    


  <p class="page__meta">

    
      
      <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
      <time datetime="2021-05-02T00:00:00-05:00">May 2, 2021</time>
    

    
      
        <br \>
      
    

    
      
      

      <i class="far fa-fw fa-clock" aria-hidden="true"></i>
      
        5 minute read
      
    

  </p>

    <p class="archive__item-excerpt" itemprop="description">Deconvolving and sharpening images is actually pretty tricky. Let’s have a look at some more advanced methods for deconvolution.
</p>
  </article>
</div>

  
    



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/imgs/teasers/st-vitus-laplace.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/deconvolution-part2/" rel="permalink">Blind Deconvolution #2: Image Priors
</a>
      
    </h2>
    


  <p class="page__meta">

    
      
      <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
      <time datetime="2021-04-09T00:00:00-05:00">April 9, 2021</time>
    

    
      
        <br \>
      
    

    
      
      

      <i class="far fa-fw fa-clock" aria-hidden="true"></i>
      
        10 minute read
      
    

  </p>

    <p class="archive__item-excerpt" itemprop="description">In order to automatically sharpen images, we need to first understand how a computer can judge how ‘natural’ an image looks.
</p>
  </article>
</div>

  
    



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/imgs/teasers/st-vitus-blur.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/deconvolution-part1/" rel="permalink">Blind Deconvolution #1: Non-blind Deconvolution
</a>
      
    </h2>
    


  <p class="page__meta">

    
      
      <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
      <time datetime="2021-03-13T00:00:00-06:00">March 13, 2021</time>
    

    
      
        <br \>
      
    

    
      
      

      <i class="far fa-fw fa-clock" aria-hidden="true"></i>
      
        6 minute read
      
    

  </p>

    <p class="archive__item-excerpt" itemprop="description">Deconvolution is one of the cornerstones of image processing. Let’s take a look at how it works.
</p>
  </article>
</div>

  
</div>

<!-- <ul class="taxonomy__index">
  
  
    <li>
      <a href="#2022">
        <strong>2022</strong> <span class="taxonomy__count">2</span>
      </a>
    </li>
  
    <li>
      <a href="#2021">
        <strong>2021</strong> <span class="taxonomy__count">7</span>
      </a>
    </li>
  
    <li>
      <a href="#2020">
        <strong>2020</strong> <span class="taxonomy__count">7</span>
      </a>
    </li>
  
</ul> -->
<!-- 





  <section id="2022" class="taxonomy__section">
    <h2 class="archive__subtitle">2022</h2>
    <div class="entries-grid">
      
        



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/imgs/teasers/gmres-teaser.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/gmres/" rel="permalink">GMRES: or how to do fast linear algebra
</a>
      
    </h2>
    


  <p class="page__meta">

    
      
      <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
      <time datetime="2022-03-10T00:00:00-06:00">March 10, 2022</time>
    

    
      
        <br \>
      
    

    
      
      

      <i class="far fa-fw fa-clock" aria-hidden="true"></i>
      
        16 minute read
      
    

  </p>

    <p class="archive__item-excerpt" itemprop="description">Linear least-squares system pop up everywhere, and there are many fast way to solve them. We’ll be looking at one such way: GMRES.
</p>
  </article>
</div>

      
        



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/imgs/teasers/discrete-function-tensor.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/discrete-function-tensor/" rel="permalink">Machine learning with discretized functions and tensors
</a>
      
    </h2>
    


  <p class="page__meta">

    
      
      <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
      <time datetime="2022-03-10T00:00:00-06:00">March 10, 2022</time>
    

    
      
        <br \>
      
    

    
      
      

      <i class="far fa-fw fa-clock" aria-hidden="true"></i>
      
        18 minute read
      
    

  </p>

    <p class="archive__item-excerpt" itemprop="description">We recently made a paper about supervised machine learning using tensors, here’s the gist of how this works.
</p>
  </article>
</div>

      
    </div>
    <a href="#page-title" class="back-to-top">Back to top &uarr;</a>
  </section>

  <section id="2021" class="taxonomy__section">
    <h2 class="archive__subtitle">2021</h2>
    <div class="entries-grid">
      
        



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/imgs/teasers/st-vitus-rank-10.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/low-rank-matrix/" rel="permalink">Low-rank matrices: using structure to recover missing data
</a>
      
    </h2>
    


  <p class="page__meta">

    
      
      <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
      <time datetime="2021-09-26T00:00:00-05:00">September 26, 2021</time>
    

    
      
        <br \>
      
    

    
      
      

      <i class="far fa-fw fa-clock" aria-hidden="true"></i>
      
        10 minute read
      
    

  </p>

    <p class="archive__item-excerpt" itemprop="description">A lot of data is naturally of ‘low rank’. I will explain what this means, and how to exploit this fact.
</p>
  </article>
</div>

      
        



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/imgs/python_docx/doc_comparison.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/python-docx/" rel="permalink">How to edit Microsoft Word documents in Python
</a>
      
    </h2>
    


  <p class="page__meta">

    
      
      <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
      <time datetime="2021-08-29T00:00:00-05:00">August 29, 2021</time>
    

    
      
        <br \>
      
    

    
      
      

      <i class="far fa-fw fa-clock" aria-hidden="true"></i>
      
        6 minute read
      
    

  </p>

    <p class="archive__item-excerpt" itemprop="description">Parsing and editing Word documents automatically can be extremely useful, but doing it in Python is not that straightforward.
</p>
  </article>
</div>

      
        



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/imgs/teasers/st-vitus-deblurred.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/deconvolution-part4/" rel="permalink">Blind deconvolution #4: Blind deconvolution
</a>
      
    </h2>
    


  <p class="page__meta">

    
      
      <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
      <time datetime="2021-05-31T00:00:00-05:00">May 31, 2021</time>
    

    
      
        <br \>
      
    

    
      
      

      <i class="far fa-fw fa-clock" aria-hidden="true"></i>
      
        6 minute read
      
    

  </p>

    <p class="archive__item-excerpt" itemprop="description">Finally, let’s look at how we can automatically sharpen images, without knowing how they were blurred in the first place.
</p>
  </article>
</div>

      
        



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/imgs/teasers/cow-weird-blur.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/deconvolution-part3/" rel="permalink">Blind Deconvolution #3: More about non-blind deconvolution
</a>
      
    </h2>
    


  <p class="page__meta">

    
      
      <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
      <time datetime="2021-05-02T00:00:00-05:00">May 2, 2021</time>
    

    
      
        <br \>
      
    

    
      
      

      <i class="far fa-fw fa-clock" aria-hidden="true"></i>
      
        5 minute read
      
    

  </p>

    <p class="archive__item-excerpt" itemprop="description">Deconvolving and sharpening images is actually pretty tricky. Let’s have a look at some more advanced methods for deconvolution.
</p>
  </article>
</div>

      
        



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/imgs/teasers/st-vitus-laplace.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/deconvolution-part2/" rel="permalink">Blind Deconvolution #2: Image Priors
</a>
      
    </h2>
    


  <p class="page__meta">

    
      
      <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
      <time datetime="2021-04-09T00:00:00-05:00">April 9, 2021</time>
    

    
      
        <br \>
      
    

    
      
      

      <i class="far fa-fw fa-clock" aria-hidden="true"></i>
      
        10 minute read
      
    

  </p>

    <p class="archive__item-excerpt" itemprop="description">In order to automatically sharpen images, we need to first understand how a computer can judge how ‘natural’ an image looks.
</p>
  </article>
</div>

      
        



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/imgs/teasers/st-vitus-blur.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/deconvolution-part1/" rel="permalink">Blind Deconvolution #1: Non-blind Deconvolution
</a>
      
    </h2>
    


  <p class="page__meta">

    
      
      <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
      <time datetime="2021-03-13T00:00:00-06:00">March 13, 2021</time>
    

    
      
        <br \>
      
    

    
      
      

      <i class="far fa-fw fa-clock" aria-hidden="true"></i>
      
        6 minute read
      
    

  </p>

    <p class="archive__item-excerpt" itemprop="description">Deconvolution is one of the cornerstones of image processing. Let’s take a look at how it works.
</p>
  </article>
</div>

      
        



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/imgs/teasers/email-time-series.jpg" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/email-time-series/" rel="permalink">Time series analysis of my email traffic
</a>
      
    </h2>
    


  <p class="page__meta">

    
      
      <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
      <time datetime="2021-02-13T00:00:00-06:00">February 13, 2021</time>
    

    
      
        <br \>
      
    

    
      
      

      <i class="far fa-fw fa-clock" aria-hidden="true"></i>
      
        6 minute read
      
    

  </p>

    <p class="archive__item-excerpt" itemprop="description">I have 15 years worth of email traffic data, let’s take a closer look and discover some fascinating patterns.
</p>
  </article>
</div>

      
    </div>
    <a href="#page-title" class="back-to-top">Back to top &uarr;</a>
  </section>

  <section id="2020" class="taxonomy__section">
    <h2 class="archive__subtitle">2020</h2>
    <div class="entries-grid">
      
        



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/imgs/teasers/music-2020.jpg" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/music_2020/" rel="permalink">2020 in music
</a>
      
    </h2>
    


  <p class="page__meta">

    
      
      <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
      <time datetime="2020-12-31T00:00:00-06:00">December 31, 2020</time>
    

    
      
        <br \>
      
    

    
      
      

      <i class="far fa-fw fa-clock" aria-hidden="true"></i>
      
        4 minute read
      
    

  </p>

    <p class="archive__item-excerpt" itemprop="description">2020 was a great year for music, I will look back and give some thoughts on the best albums that came out in 20202.
</p>
  </article>
</div>

      
        



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/imgs/teasers/bayes-exam.jpg" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/bayes_exam/" rel="permalink">Modeling uncertainty in exam scores
</a>
      
    </h2>
    


  <p class="page__meta">

    
      
      <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
      <time datetime="2020-11-09T00:00:00-06:00">November 9, 2020</time>
    

    
      
        <br \>
      
    

    
      
      

      <i class="far fa-fw fa-clock" aria-hidden="true"></i>
      
        3 minute read
      
    

  </p>

    <p class="archive__item-excerpt" itemprop="description">We use exams to determine how much a student knows, but exams aren’t perfect. How can we estimate the uncertainty in students’ exams scores?
</p>
  </article>
</div>

      
        



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/imgs/teasers/validation-data.jpg" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/validation-size/" rel="permalink">How big should my validation set be?
</a>
      
    </h2>
    


  <p class="page__meta">

    
      
      <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
      <time datetime="2020-08-26T00:00:00-05:00">August 26, 2020</time>
    

    
      
        <br \>
      
    

    
      
      

      <i class="far fa-fw fa-clock" aria-hidden="true"></i>
      
        12 minute read
      
    

  </p>

    <p class="archive__item-excerpt" itemprop="description">Cross validation is extremely important, but how should we choose the size of our validation and test sets?
</p>
  </article>
</div>

      
        



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/imgs/teasers/lastfm.jpg" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/lastfm/" rel="permalink">How do my music preferences evolve?
</a>
      
    </h2>
    


  <p class="page__meta">

    
      
      <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
      <time datetime="2020-08-12T00:00:00-05:00">August 12, 2020</time>
    

    
      
        <br \>
      
    

    
      
      

      <i class="far fa-fw fa-clock" aria-hidden="true"></i>
      
        5 minute read
      
    

  </p>

    <p class="archive__item-excerpt" itemprop="description">I use last.fm to track my music listening. Let’s look at my data to discover how my musical preferences evolve over time.
</p>
  </article>
</div>

      
        



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/imgs/teasers/normal-data.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/normal-data/" rel="permalink">Is my data normal?
</a>
      
    </h2>
    


  <p class="page__meta">

    
      
      <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
      <time datetime="2020-08-10T00:00:00-05:00">August 10, 2020</time>
    

    
      
        <br \>
      
    

    
      
      

      <i class="far fa-fw fa-clock" aria-hidden="true"></i>
      
        6 minute read
      
    

  </p>

    <p class="archive__item-excerpt" itemprop="description">Normally distributed data is great, but how do you know whether your data is normally distributed?
</p>
  </article>
</div>

      
        



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/imgs/teasers/figure-skating.jpg" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/figure-skating/" rel="permalink">Bias in figure skating judging
</a>
      
    </h2>
    


  <p class="page__meta">

    
      
      <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
      <time datetime="2020-06-20T00:00:00-05:00">June 20, 2020</time>
    

    
      
        <br \>
      
    

    
      
      

      <i class="far fa-fw fa-clock" aria-hidden="true"></i>
      
        3 minute read
      
    

  </p>

    <p class="archive__item-excerpt" itemprop="description">Judging in figure skating is biased. Let’s use data science to figure out just how bad the issue is.
</p>
  </article>
</div>

      
        



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/imgs/teasers/first-post.jpg" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/first-post/" rel="permalink">First post
</a>
      
    </h2>
    


  <p class="page__meta">

    
      
      <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
      <time datetime="2020-06-19T07:19:44-05:00">June 19, 2020</time>
    

    
      
        <br \>
      
    

    
      
      

      <i class="far fa-fw fa-clock" aria-hidden="true"></i>
      
        less than 1 minute read
      
    

  </p>

    <p class="archive__item-excerpt" itemprop="description">My first post in this blog
</p>
  </article>
</div>

      
    </div>
    <a href="#page-title" class="back-to-top">Back to top &uarr;</a>
  </section>
 -->

  </div>
</div>
    </div>

    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    <!-- 
      <li><strong>Contact info and socials</strong></li>
     -->

    
      
        
      
        
      
        
      
        
      
        
      
        
      
    

    <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2022 Rik Voorhaar. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>







  <script>
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'G-Q5W21THKW2']);
  
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>









  </body>
</html>
